{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Function Calling in Nutshell\n",
    "#### Exploring Function Calling with Azure Open AI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the dependencies for this notebook\n",
    "%pip install -q openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Create `.env` file in your root directory and add your Azure Open AI key and Azure Open AI endpoint in it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Azure Open AI\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "# Details about supported API versions: https://learn.microsoft.com/en-us/azure/ai-services/openai/reference\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2024-02-01\"\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "llm = AzureOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `tools` model Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function `\"NER\"` with the `\"tools\"` model parameter.\n",
    "\n",
    "The function returns the Named Entities in the input text. \n",
    "\n",
    "Note that the function in this example is a hypothetical one, it's not implemented in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I use the latest gpt-4-turbo-2024-09-04 model\n",
    "\n",
    "response = llm.chat.completions.create(\n",
    "    model=\"gpt-4-2024-09-04\",\n",
    "    temperature=0,\n",
    "    messages=[\n",
    "        {\"role\":\"system\",\"content\":\"Think carefully, and then analyze the text as instructed. If a text doesn't contain any of named entities, just provide an empty object.\"},\n",
    "        {\"role\": \"user\", \"content\": \"My name is Vlad and I'm working at Microsoft as a Solutions Architect.\"},\n",
    "    ],\n",
    "    tools=[\n",
    "\n",
    "        {\"type\": \"function\",\n",
    "         \"function\": {\n",
    "             'name': 'NER',\n",
    "             'description': 'Extract all named entities in the provided context. NER stands for Named Entity Recognition',\n",
    "             'parameters': {'type': 'object',\n",
    "                            'properties': {'person': {'description': 'person name', 'type': 'string'},\n",
    "                                           'company': {'description': 'company name', 'type': 'string'},\n",
    "                                           'job_title': {'description': 'person job title', 'type': 'string'}},\n",
    "                            'required': ['person', 'company', 'job_title']}}\n",
    "         }\n",
    "\n",
    "    ],\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9OkJbZ0e8C2u93EQRbvZdjxIFryVj', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_pcgXnVErWFZqFULBSEStxpA2', function=Function(arguments='{\"person\":\"Vlad\",\"company\":\"Microsoft\",\"job_title\":\"Solutions Architect\"}', name='NER'), type='function')]), content_filter_results={})], created=1715684935, model='gpt-4-turbo-2024-04-09', object='chat.completion', system_fingerprint='fp_f5ce1e47b6', usage=CompletionUsage(completion_tokens=26, prompt_tokens=121, total_tokens=147), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The content is empty.\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tool_calls'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response.choices[0].finish_reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NER'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function name\n",
    "response.choices[0].message.tool_calls[0].function.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"person\":\"Vlad\",\"company\":\"Microsoft\",\"job_title\":\"Solutions Architect\"}'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# functions arguments\n",
    "response.choices[0].message.tool_calls[0].function.arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First `finish_reason`='tools_calls' means that the model decided to call the function.\n",
    "\n",
    "The `tool_calls`array contains ChatCompletionMessageToolCall object which in turn has Function object which contains the function name and the parameters passed to the function.\n",
    "\n",
    "In other words the model not only decided to call the function NER but also extracted the Named Entities from the input context as an input parameters.\n",
    "\n",
    "The important point here is that the output is well structured and easy to parse or convert to Python dictionary as shown below:\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Microsoft'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model output to a dictionary\n",
    "str_out = response.choices[0].message.tool_calls[0].function.arguments\n",
    "d = json.loads(str_out)\n",
    "d[\"company\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if the text doesn't contain any Named Entities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.chat.completions.create(\n",
    "    model=\"gpt-4-2024-09-04\",\n",
    "    temperature=0,\n",
    "    messages=[\n",
    "        {\"role\":\"system\",\"content\":\"Think carefully, and then analyze the text as instructed.If a text doesn't contain any of named entities, just provide an empty object.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello how are you today?\"},\n",
    "    ],\n",
    "    tools=[\n",
    "\n",
    "        {\"type\": \"function\",\n",
    "           \"function\": {\n",
    "             'name': 'NER',\n",
    "             'description': 'Extract all named entities in the provided context. NER stands for Named Entity Recognition',\n",
    "             'parameters': {'type': 'object',\n",
    "                            'properties': {'person': {'description': 'person name', 'type': 'string'},\n",
    "                                           'company': {'description': 'company name', 'type': 'string'},\n",
    "                                           'job_title': {'description': 'person job title', 'type': 'string'}},\n",
    "                            'required': ['person', 'company', 'job_title']}}\n",
    "         },\n",
    "    ],\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9OjlhAI46FEKSZ5V6zDfnTB9xyztL', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to assist you. How can I help you today?\", role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1715682833, model='gpt-4-turbo-2024-04-09', object='chat.completion', system_fingerprint='fp_f5ce1e47b6', usage=CompletionUsage(completion_tokens=34, prompt_tokens=84, total_tokens=118), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm here to help you! How can I assist you today?\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stop'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the finish_reason is : \"stop\"\n",
    "response.choices[0].finish_reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool_calls is empty\n",
    "response.choices[0].message.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `finish_reason` is `stop` in this case. This state means the model has a final response and there is no need to call any additonal function. \n",
    "We'll use the finish reason to build agentic flows where there are multiple looping calls to the functions and finish_reason serves as a stopping criteria.\n",
    "\n",
    "Pay attention to the `tool_calls` array which is empty in this case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallel Function calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we have more than one function ? \n",
    "\n",
    "Open AI supports `Parallel function calling`, when in one request to the model, the model decides that multiple functions should be called.\n",
    "\n",
    "The model decides to call the function based on the context and the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that latest gpt-4-turbo-2024-09-04 model doesn't support yet Parallel Function calls, so I use here another gpt-4-turbo version\n",
    "response = llm.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    temperature=0,\n",
    "    messages=[\n",
    "        {\"role\":\"system\",\"content\":\"Think carefully, and then analyze the text as instructed\"},\n",
    "        {\"role\": \"user\", \"content\": \"My name is Vlad and I'm working at Microsoft as a Solutions Architect. I love OpenAI.\"},\n",
    "    ],\n",
    "    tools=[\n",
    "\n",
    "        {\"type\": \"function\",\n",
    "           \"function\": {\n",
    "             'name': 'NER',\n",
    "             'description': 'Extract all named entities in the provided context. NER stands for Named Entity Recognition',\n",
    "             'parameters': {'type': 'object',\n",
    "                            'properties': {'person': {'description': 'person name', 'type': 'string'},\n",
    "                                           'company': {'description': 'company name', 'type': 'string'},\n",
    "                                           'job_title': {'description': 'person job title', 'type': 'string'}},\n",
    "                            'required': ['person', 'company', 'job_title']}}\n",
    "         },\n",
    "        {\"type\": \"function\",\n",
    "           \"function\": {\n",
    "                \"name\": \"SentimentAnalysis\",\n",
    "                \"description\": \"Extract sentiment in the provided context. The sentiment value must be on those: `positive`, `negative` or `neutral`.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"sentiment\": {\"description\": \"sentiment value\",\"type\": \"string\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"sentiment\"]}}\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9OkNHplXc3K1Q3tygBpjTqRADRDCg', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_bDvRTFK5OoCk72yYgdDxFFdO', function=Function(arguments='{\"person\": \"Vlad\", \"company\": \"Microsoft\", \"job_title\": \"Solutions Architect\"}', name='NER'), type='function'), ChatCompletionMessageToolCall(id='call_aftIDnfZWqP6cqOC5JMQALCf', function=Function(arguments='{\"sentiment\": \"positive\"}', name='SentimentAnalysis'), type='function')]), content_filter_results={})], created=1715685163, model='gpt-4', object='chat.completion', system_fingerprint='fp_2f57f81c11', usage=CompletionUsage(completion_tokens=98, prompt_tokens=156, total_tokens=254), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tool_calls'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].finish_reason"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tool_calls array now contains multiple ChatCompletionMessageToolCall objects, each of which contains a Function object with the function name and the parameters passed to the function.\n",
    "\n",
    "Each tool has an unique `ID`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletionMessageToolCall(id='call_bDvRTFK5OoCk72yYgdDxFFdO', function=Function(arguments='{\"person\": \"Vlad\", \"company\": \"Microsoft\", \"job_title\": \"Solutions Architect\"}', name='NER'), type='function'),\n",
       " ChatCompletionMessageToolCall(id='call_aftIDnfZWqP6cqOC5JMQALCf', function=Function(arguments='{\"sentiment\": \"positive\"}', name='SentimentAnalysis'), type='function')]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER\n",
      "{\"person\": \"Vlad\", \"company\": \"Microsoft\", \"job_title\": \"Solutions Architect\"}\n",
      "SentimentAnalysis\n",
      "{\"sentiment\": \"positive\"}\n"
     ]
    }
   ],
   "source": [
    "for func in response.choices[0].message.tool_calls:\n",
    "    print(func.function.name)\n",
    "    print(func.function.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_out = response.choices[0].message.tool_calls[1].function.arguments\n",
    "d = json.loads(str_out)\n",
    "d[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
